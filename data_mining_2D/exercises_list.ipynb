{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from os import path\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage.feature import local_binary_pattern as lbp, greycoprops,greycomatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing images\n",
    "datasetFolder = path.join('.', 'numbers_dataset')\n",
    "datasetImages = ['1_1.png', '1_2.jpg','1_4.png',  '1_5.jpg',  '1_6.png',  '1.jpg']\n",
    "\n",
    "#reading images and converting them to grayscale\n",
    "images = [cv.imread(path.join(datasetFolder, p)) for p in datasetImages]\n",
    "images = [cv.cvtColor(image, cv.COLOR_BGR2GRAY) for image in images]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating chainCode function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def chainCode(img):\n",
    "\n",
    "    #Converting img to grayscale\n",
    "    #img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    #thresholding img\n",
    "    _, imgThresholded = cv.threshold(img, 200, 255,cv.THRESH_BINARY)\n",
    "\n",
    "    #maybe the input image has a white background, so we need to invert the colors\n",
    "    #we are assuming that the object is smaller than the background\n",
    "    white_pixels,black_pixels = np.where(imgThresholded==255),np.where(imgThresholded==0)\n",
    "    if len(white_pixels[0]) > len(black_pixels[0]):\n",
    "        imgThresholded = cv.bitwise_not(imgThresholded)\n",
    "\n",
    "    #dilating the object\n",
    "    element = cv.getStructuringElement(shape=cv.MORPH_RECT, ksize=(3,3))\n",
    "    imgDilated = cv.dilate(imgThresholded, element)\n",
    "\n",
    "    #subtracting to only get the edges\n",
    "    imgDilated = imgDilated - imgThresholded\n",
    "\n",
    "    #finding the first white pixel\n",
    "    initialPoint = np.where(imgDilated==255)\n",
    "    initialPoint = (initialPoint[0][0], initialPoint[1][0])\n",
    "\n",
    "    #deleting variables which will not be usefull anymore\n",
    "    del imgThresholded, white_pixels, black_pixels\n",
    "    \n",
    "    ret_vec = []\n",
    "    point = initialPoint\n",
    "    \n",
    "    dilatedCopy = np.zeros_like(imgDilated)\n",
    "    while True:\n",
    "        \n",
    "        #verify if the right pixel is an edge \n",
    "        if imgDilated[point[0],point[1]+1] == 255:\n",
    "            ret_vec.append(0)\n",
    "            point = (point[0],point[1]+1)\n",
    "            imgDilated[point] = 0\n",
    "            dilatedCopy[point] = 180\n",
    "\n",
    "        #verify if the below pixel is an edge\n",
    "        elif imgDilated[point[0]+1,point[1]] == 255:\n",
    "            ret_vec.append(6)\n",
    "            point = (point[0]+1,point[1])\n",
    "            imgDilated[point] = 0\n",
    "            dilatedCopy[point] = 180\n",
    "        \n",
    "\n",
    "        #verify if the left pixel is an edge\n",
    "        elif imgDilated[point[0],point[1]-1] == 255:\n",
    "            ret_vec.append(4)\n",
    "            point = (point[0],point[1]-1)\n",
    "            imgDilated[point] = 0\n",
    "            dilatedCopy[point] = 180\n",
    "\n",
    "        #verify if the above pixel is an edge\n",
    "        elif imgDilated[point[0]-1,point[1]] == 255:\n",
    "            ret_vec.append(2)\n",
    "            point = (point[0]-1,point[1])\n",
    "            imgDilated[point] = 0\n",
    "            dilatedCopy[point] = 180\n",
    "\n",
    "        #verify if the right-down pixel is an edge \n",
    "        elif imgDilated[point[0]+1,point[1]+1] == 255:\n",
    "            ret_vec.append(7)\n",
    "            point = (point[0]+1,point[1]+1)\n",
    "            imgDilated[point] = 0\n",
    "            dilatedCopy[point] = 180\n",
    "\n",
    "        #verify if the left-down pixel is an edge \n",
    "        elif imgDilated[point[0]+1,point[1]-1] == 255:\n",
    "            ret_vec.append(5)\n",
    "            point = (point[0]+1,point[1]-1)\n",
    "            imgDilated[point] = 0\n",
    "            dilatedCopy[point] = 180\n",
    "\n",
    "        #verify if the left-up pixel is an edge \n",
    "        elif imgDilated[point[0]-1,point[1]-1] == 255:\n",
    "            ret_vec.append(3)\n",
    "            point = (point[0]-1,point[1]-1)\n",
    "            imgDilated[point] = 0\n",
    "            dilatedCopy[point] = 180\n",
    "\n",
    "        #verify if the right-up pixel is an edge \n",
    "        elif imgDilated[point[0]-1,point[1]+1] == 255:\n",
    "            ret_vec.append(1)\n",
    "            point = (point[0]-1,point[1]+1)\n",
    "            imgDilated[point] = 0\n",
    "            dilatedCopy[point] = 180\n",
    "\n",
    "        #cv.imshow('dilatedCopy', dilatedCopy)\n",
    "        #cv.waitKey(5)\n",
    "\n",
    "        #if we reach the initialPoint then we break    \n",
    "        if point==initialPoint: break\n",
    "    return ret_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 6, 4, 4, 6, 4, 4, 6, 4, 4, 4, 6, 4, 4, 6, 4, 4, 6, 4, 4, 4, 6, 4, 4, 6, 4, 4, 4, 6, 4, 4, 4, 6, 4, 4, 6, 4, 4, 4, 6, 4, 4, 4, 4, 6, 4, 4, 4, 6, 4, 4, 4, 6, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "cd = chainCode(images[0])\n",
    "print(cd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesChainCodes = [chainCode(image) for image in images]\n",
    "plt.subplots_adjust(hspace = 0.77)\n",
    "for i,cd in enumerate(imagesChainCodes):\n",
    "    plt.subplot(len(imagesChainCodes),1,i+1)\n",
    "    plt.plot(imagesChainCodes[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawChainCode(chainCode, retImgSize=(800,640), startPixel=None, finishIfIncomplete=False):\n",
    "    #Creating return image\n",
    "    retImg = np.zeros((retImgSize[0], retImgSize[1]))\n",
    "    \n",
    "    #if no start point is defined then we set a arbitray start point\n",
    "    if startPixel==None:\n",
    "        #count how many times the chainCode go down, in other words, how many 6 we have\n",
    "        count = len([x for x in chainCode if x==6])+20\n",
    "        if count>retImgSize[0]:\n",
    "            print(\"The figure is larger than the image, please use 'retImgSize' parameter to resize the return image.\")\n",
    "            return\n",
    "        point = (int(retImgSize[0]-count), int(retImgSize[1]/2))\n",
    "        startPixel = point\n",
    "        \n",
    "    else:\n",
    "        point = startPixel\n",
    "    \n",
    "    for value in chainCode:\n",
    "        if value==0:            \n",
    "            point = (point[0],point[1]+1)\n",
    "            retImg[point] = 255\n",
    "        if value==1:            \n",
    "            point = (point[0]-1,point[1]+1)\n",
    "            retImg[point] = 255\n",
    "        if value==2:            \n",
    "            point = (point[0]-1,point[1])\n",
    "            retImg[point] = 255\n",
    "        if value==3:            \n",
    "            point = (point[0]-1,point[1]-1)\n",
    "            retImg[point] = 255\n",
    "        if value==4:            \n",
    "            point = (point[0],point[1]-1)\n",
    "            retImg[point] = 255\n",
    "        if value==5:            \n",
    "            point = (point[0]+1,point[1]-1)\n",
    "            retImg[point] = 255\n",
    "        if value==6:            \n",
    "            point = (point[0]+1,point[1])\n",
    "            retImg[point] = 255\n",
    "        if value==7:            \n",
    "            point = (point[0]+1,point[1]+1)\n",
    "            retImg[point] = 255\n",
    "    \n",
    "    if finishIfIncomplete and startPixel!=point:\n",
    "        if retImg is not None:\n",
    "            a = cv.line(retImg, (startPixel[1],startPixel[0]), (point[1],point[0]), color=(255))\n",
    "            return a\n",
    "\n",
    "    return retImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawedImg = drawChainCode(cd)\n",
    "cv.imshow('drawedImg', drawedImg)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw all chain code in the imagesChainCodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cd in imagesChainCodes:\n",
    "    a = drawChainCode(cd)\n",
    "    cv.imshow('drawedImg',a)\n",
    "    cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackBoxNormalization(arrayOfCds):\n",
    "    retArray = []\n",
    "    \n",
    "    #choose the minimum value between the arrays lengths\n",
    "    normalizedArrayLength = np.min([len(array) for array in arrayOfCds])\n",
    "    \n",
    "    \n",
    "    for array in arrayOfCds:\n",
    "        if len(array)!=normalizedArrayLength:\n",
    "            arrayLen = len(array) #get the current array length\n",
    "            step = arrayLen/normalizedArrayLength #find the step\n",
    "\n",
    "            normalizedArray = []\n",
    "            normalizedArray.append(array[0]) #append the firts value\n",
    "            idx,aux = 0,0.0\n",
    "            \n",
    "            for x in range(normalizedArrayLength-1):\n",
    "                aux +=step\n",
    "                a = int(aux)\n",
    "                idx+=a\n",
    "                aux -= a\n",
    "                if idx > arrayLen-1:\n",
    "                    break\n",
    "                else:\n",
    "                    normalizedArray.append(array[idx])\n",
    "            \n",
    "            retArray.append(normalizedArray)\n",
    "        else:\n",
    "            retArray.append(array)\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of chain codes before normalization: \n",
      "1350\n",
      "1682\n",
      "1319\n",
      "965\n",
      "300\n",
      "2001\n",
      "\n",
      "Length of chain codes after normalization: \n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "#printing chain codes length before normalization\n",
    "print(\"Length of chain codes before normalization: \")\n",
    "[print(len(x)) for x in imagesChainCodes]\n",
    "\n",
    "normalizedArrayOfCds = blackBoxNormalization(imagesChainCodes)\n",
    "\n",
    "#printing chain codes length after normalization\n",
    "print(\"\\nLength of chain codes after normalization: \")\n",
    "[print(len(x)) for x in normalizedArrayOfCds]\n",
    "\n",
    "#drawing the normalized chain codes\n",
    "for i, image in enumerate(normalizedArrayOfCds):\n",
    "    cv.imshow('input image',drawChainCode(imagesChainCodes[i]))\n",
    "    \n",
    "    #finishIfIncomplete parameter in the drawChainCode function will complete the number if the chain code\n",
    "    #it's not enough to draw the whole number\n",
    "    cv.imshow('normalized Image', drawChainCode(image, retImgSize=(600,600), finishIfIncomplete=True))\n",
    "    cv.waitKey(0)\n",
    "    \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One of the chain code has the length of 300, which will make the others chain code suffer a lot with lost of information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from random import randint\n",
    "\n",
    "def newNumber(normalizedArrayOfCds):\n",
    "    ret = []\n",
    "    #finding the mode for each column of normalized chain codes matrix\n",
    "    df = pd.DataFrame(normalizedArrayOfCds)\n",
    "    mode = list(df.mode().iloc[0])#most frequent values of each column\n",
    "    for x in range(len(df.columns)):\n",
    "        a = list(df.iloc[:,x]) #a is an entire column\n",
    "        #find the most frequent value which is diferrent from the mode\n",
    "        i = reduce(lambda x, y: x if x>y and x!=mode[x] else y, a)\n",
    "        #if the result of randint is 1 we append the mode, else we append the second most frequent value\n",
    "        if randint(0,1)==1:\n",
    "            ret.append(mode[x])\n",
    "        else:\n",
    "            ret.append(i)\n",
    "    return ret\n",
    "        \n",
    "newCD = newNumber(normalizedArrayOfCds)\n",
    "cv.imshow('newCD', drawChainCode(newCD, retImgSize=(600,600), finishIfIncomplete=True))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuresExtractor(image, lbp_p=8, lbp_r=1):\n",
    "    '''\n",
    "    Columns Description:\n",
    "    \n",
    "    0-11 = GLCM features:\n",
    "        Contrast[0 rad], Contrast[pi/2 rad], dissimilarity[0 rad], dissimilarity[pi/2 rad]\n",
    "        homogeneity[0 rad], homogeneity[pi/2 rad], energy[0 rad], energy[pi/2 rad]\n",
    "        correlation[0 rad], correlation[pi/2 rad], ASM[0 rad], ASM[pi/2 rad]\n",
    "    \n",
    "    12-18 = HuMoments\n",
    "\n",
    "    19-..  = LBP Features\n",
    "    \n",
    "    '''\n",
    "\n",
    "    glcmFeatures = [\"contrast\", \"dissimilarity\", \"homogeneity\", \"energy\", \"correlation\", \"ASM\"]\n",
    "    ret = [] #return list\n",
    "    \n",
    "    #GLCM Values\n",
    "    #for each image we will compute the features in props\n",
    "    #each computed feature will return two values, one for the 0 rad and other for pi/2 rad\n",
    "    glcmIm = greycomatrix(image, [1], [0, np.pi/2], levels=256)\n",
    "    for feature in glcmFeatures:\n",
    "        p = greycoprops(glcmIm,feature)\n",
    "        [ret.append(x) for x in p[0]]\n",
    "\n",
    "    #Hu Moments\n",
    "    huMoments = cv.HuMoments(cv.moments(image))\n",
    "    huMoments =  np.transpose(huMoments)\n",
    "    [ret.append(x) for x in huMoments[0]]\n",
    "    \n",
    "    #lbp features\n",
    "    a = lbp(image, lbp_p, lbp_r, 'uniform')\n",
    "    a = plt.hist(a.ravel())\n",
    "    [ret.append(x) for x in a[0]]\n",
    "    [ret.append(x) for x in a[1]]\n",
    "    \n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesFeaturesDataset = pd.DataFrame([featuresExtractor(i) for i in images])\n",
    "display(imagesFeaturesDataset)\n",
    "imagesFeaturesDataset.to_csv(index=False, path_or_buf=\"./dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bolide Detector\n",
    "    Bolides are meteors that explode in the atmosphere, they usually don't represent any danger to the human kind but tracking their position is a good way to verify the meteors activity around the earth, which can prevent bigger problems. In Brazil and around the world the astronomers have cameras to monitor the sky at night, a good example is the BRAMON (Brazil Meteor Observation Network). This work uses BRAMON cameras to train the algorithm and test it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2dFeatureExtraction",
   "language": "python",
   "name": "2dfeatureextraction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
