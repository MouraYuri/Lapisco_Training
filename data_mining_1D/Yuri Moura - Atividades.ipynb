{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atividades\n",
    "===\n",
    "\n",
    "Essas atividade s√£o relativas a aulas de extra√ß√£o de atributos e selec√£o de atributos. \n",
    "- Link para video: https://drive.google.com/file/d/13LLQGLt7QsjKshBXgUdJ4RVOT8N252cU/view\n",
    "- Link para apresenta√ß√£o: https://docs.google.com/presentation/d/1wctFgQe7TSlBEypZbVQqqsfrnpSgOeXPSO-mCJ6jIz4\n",
    "\n",
    "\n",
    "> Lembre de criar uma `virtualenv` com os `requirements.txt` do reposit√≥rio.\n",
    "\n",
    "> Lembre de criar uma `kernel` do jupyter para seus desenvolvimentos\n",
    "\n",
    "> **MANTENHA** essa arquivo no local padr√£o do reposit√≥rio. Detro da pasta **feature_extraction_and_feature_selection**.\n",
    "\n",
    "> Enviei apenas o seu notebook para corre√ß√£o. N√£o √© necess√°rio enviar nenhum outro arquivo. Siga o padr√£o `Atividades-<NOME-DO-ALUNO>.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Realizar a extra√ß√£o de atributos utilzando as t√©cnicas Fourier e HOS nas bases de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dados de falhas em aerogeradores\n",
    "\n",
    "As orienta√ß√µes abaixo devem ser seguidas antes de iniciar os trabalhos\n",
    "\n",
    "> Todo os arquivos nomeados com `v000_ ... .csv` s√£o referentes a essa base.\n",
    "\n",
    "> A classe referente ao dado est√° representada por uma TAG no nome do arquivo da seguinte forma: `v000_NORMAL_ ... .csv` √© o dado referente a classe de funcionamento normal do gerador. A TAG `v000_SC_LI_LVL3_ ... .csv` √© a classe referente a falha tipo 1 e continua. N√£o se preocupem com a ordem de enumera√ß√£o das classes nesse momento.\n",
    "\n",
    "> H√° 5 arquivos na pasta.\n",
    "\n",
    "> Utilizar as colunas a `Current_R`, `Current_S`, `Current_T` para realizar extra√ß√£o de atributos. Perceba que cada coluna √© referente a uma sinal de corrente el√©trica, portanto cada um s√£o representados vetores de dimens√µes $1x50000$.\n",
    "\n",
    "> Antes de realizar a extra√ß√£o de atributos deve-se dividir cada sinal em 10 partes de tamanho $1x5000$. A ideia aqui √© aumentar o n√∫mero de amostra da base de dados por 10. Pense que cada parte √© um recorte do sinal, e ao serem concatenadas retornar√£o o sinal original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing feature extraction module  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/navarmn/feature_extraction_signal.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction_signal.src import feature_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing pandas and others tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregue a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = os.path.join('.', 'datasets')\n",
    "DATAFILES = [\n",
    "    'v000_FAULT_SC_HI_LVL2_FR6000_FG5942_L000_0,6IN_SENSORC.csv',\n",
    "    'v000_FAULT_SC_LI_LVL3_FR4500_FG4365_L000_0,8IN_SENSORC.csv',\n",
    "    'v000_FAULT_SC_LI_LVL3_FR6000_FG5927_L000_0,4IN_SENSORC.csv',\n",
    "    'v000_NORMAL_FR4500_FG4385_L000_1,0IN_SENSORC.csv',\n",
    "    'v000_NORMAL_FR6000_FG5955_L000_0,5IN_SENSORC.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We are going to have an array which each element is a dataframe with the full signal\n",
    "'''\n",
    "\n",
    "signals = [pd.read_csv(os.path.join(dataset_folder, DATAFILES[x])).iloc[:, :3] for x in range(len(DATAFILES))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code below will split the dataframe in an array with N dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataframe(df, slices=10):\n",
    "    #collecting number of rows and columns\n",
    "    df_rows, df_columns = df.shape\n",
    "    \n",
    "    #defining the slice\n",
    "    slice = int(df_rows/slices)\n",
    "    \n",
    "    #defining variables to start spliting the dataframe\n",
    "    prev_slice, current_slice = 0, 0\n",
    "    slices_array = [] #array that will receive the slices\n",
    "    for x in range(slices):\n",
    "        #update the prev and current slice variables and append the slice to slices_array \n",
    "        prev_slice = current_slice\n",
    "        current_slice+=slice\n",
    "        slices_array.append(df.iloc[prev_slice:current_slice])\n",
    "    return slices_array    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining a sliced dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinDataframe(array_of_dfs):\n",
    "    dataframe = pd.DataFrame([])\n",
    "    for df in array_of_dfs:\n",
    "        dataframe = dataframe.append(df, ignore_index=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now we are going to split each signal, that by now are dataframes. So at the end of the process we\n",
    "will have an array which each element it will be an another array with the sliced signals.\n",
    "\n",
    "[[slice1DF, slice2DF, ..., slice10DF], ...]\n",
    "\n",
    "'''\n",
    "\n",
    "splited_signals = []\n",
    "for signal in signals:\n",
    "    splited_signals.append(splitDataframe(signal))\n",
    "\n",
    "    \n",
    "#selecting just the three fisrt columns of the splited dataframe\n",
    "#array_of_dfs = [df.iloc[:, :3] for df in array_of_dfs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Comparativo da m√©dia do sinal e sua distribui√ß√£o\n",
    "\n",
    "- Realize o calculo da m√©dia e desvio padr√£o em cada um dos sinais e exiba o resultado em um dataframe. Discuta suas conclus√µes.\n",
    "\n",
    "**help**: utilize as func√µes nativas do numpy ou do pandas. Lembre que o sinal √© uma senoide, qual a m√©dia em uma senoide sim√©trica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mean_and_std(array_of_dfs, how='slices'):\n",
    "    '''\n",
    "    Two types of use:\n",
    "    full: Use the full signal to calculate the mean and the standard deviation.\n",
    "    \n",
    "    slices: Use the slices to calculate the mean and the standard deviation and return the result\n",
    "    of each slice as a Dataframe\n",
    "    '''\n",
    "\n",
    "    #dataframes that will be merged\n",
    "    df_mean, df_std = pd.DataFrame([]),pd.DataFrame([])\n",
    "    \n",
    "    #dataframe that will be returned\n",
    "    return_df = pd.DataFrame([])\n",
    "    \n",
    "    #joins the dataframe\n",
    "    dataframe = joinDataframe(array_of_dfs)\n",
    "\n",
    "    #getting columns names and changing them\n",
    "    cols_names = dataframe.columns\n",
    "    mean_names, std_names = ['mean_'+name for name in cols_names],['std_'+name for name in cols_names]\n",
    "    \n",
    "    if how == 'full':\n",
    "        \n",
    "        #calculating the mean and the standard deviation of the dataframe\n",
    "        serie_mean, serie_std = dataframe.mean(), dataframe.std()\n",
    "        \n",
    "        #changing the index of the series\n",
    "        serie_mean.index,serie_std.index = mean_names,std_names\n",
    "        \n",
    "        #returns the mean series concatenated with the std series\n",
    "        return pd.concat([serie_mean, serie_std], join='outer', sort=False)\n",
    "\n",
    "    if how == 'slices':\n",
    "        #deleting dataframe variable that will not be used anymore\n",
    "        del dataframe\n",
    "        \n",
    "        for df in array_of_dfs:\n",
    "\n",
    "            #calculating the mean and the standard deviation of the current dataframe(df)\n",
    "            serie_mean, serie_std = df.mean(), df.std()\n",
    "\n",
    "            #changing the index of the series\n",
    "            serie_mean.index,serie_std.index = mean_names,std_names\n",
    "\n",
    "            #appending the serie_mean and the serie_std to df_mean and df_std, respectively\n",
    "            df_mean, df_std = df_mean.append(serie_mean, ignore_index=True), df_std.append(serie_std, ignore_index=True, sort=False)\n",
    "    \n",
    "        #Merging the two dataframes (df_mean and df_std)\n",
    "        return_df = df_mean.merge(df_std, left_index=True, right_index=True, how='outer')\n",
    "        \n",
    "            \n",
    "    return return_df\n",
    "\n",
    "for i, splited_signal in enumerate(splited_signals):\n",
    "    print('\\n'+DATAFILES[i]+'\\nSignal {}'.format(i))\n",
    "    display(mean_and_std(splited_signal, how='slices'))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### √à poss√≠vel notar que temos a m√©dia do sinal por volta de zero por causa de sua caracter√≠stica peri√≥dica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Extra√ß√£o de atributos no sinal\n",
    "\n",
    "- Utilize o c√≥digo de `feature_extraction_signal` em: https://github.com/navarmn/feature_extraction_signal\n",
    "- Use as classes `Fourier` e `HOS` de maneira adequada. Lembre do m√©todo `.transform()`.\n",
    "- Na classe `Fourier`utilize os par√¢metros: `fs=5000`; o valor de fundamental est√° na TAG do nome em `_FG5955_`significa `fundamental=59.55`. `harmonics=(0.5, 1, 1.5, 2.5, 3, 5, 7)`, mas sintam-se √† vontade para buscar outras harm√¥nicas;\n",
    "- Os r√≥tulos devem serem impostos de acordo com a descri√ß√£o da tag feita cima. \n",
    "- Monte um dataframe que contenham os atributos em cada coluna e a √∫tlima com o r√≥tulo. Concatene os artibutos extra√≠dos da `Current_R`, `Current_S` e `Current_T`.\n",
    "- Dever√° ser feito um dataframe para os atributos de Fourier e um para os atributos de HOS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting fundamental frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_freq = [] #fundamental frequencies\n",
    "\n",
    "#simple string manipulation to extract a fundamental frequencies from the datafile's name\n",
    "for file_name in DATAFILES:\n",
    "    a = file_name.split('_')\n",
    "    fr = a[2] if a[1] == 'NORMAL' else a[5] \n",
    "    fund_freq.append(float(fr[2:])/100)\n",
    "print(\"fund_freq =\",fund_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = splited_signals[0][0]\n",
    "display(data['Current_R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fourier feature extractor\n",
    "ffe = feature_extraction.Fourier(fundamental=60.00, fs=5000.0, harmonics=(0.5, 1, 1.5, 2.5, 3, 5, 7))\n",
    "out_fourier = ffe.transform(data['Current_R'])\n",
    "display(out_fourier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = joinDataframe(splited_signals[0])\n",
    "#Fourier feature extractor\n",
    "ffe = feature_extraction.Fourier(fundamental=60.00, fs=5000.0, harmonics=(0.5, 1, 1.5, 2.5, 3, 5, 7))\n",
    "out_fourier = ffe.transform(data['Current_R'])\n",
    "display(out_fourier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) An√°lise explorat√≥ria na base criada com os extratores de atributos\n",
    "- Use a ferramenta `pandas-profiling` https://github.com/pandas-profiling/pandas-profiling\n",
    "- Fa√ßa um resumo do relat√≥rio, destacando os principais pontos gerados na base.\n",
    "- Fa√ßa uma an√°lise para cada uma das bases:\n",
    "    1. Features criada com Fourier\n",
    "    2. Features criada com HOS\n",
    "    3. Combina√ß√£o das duas features (Fourier + HOS). \n",
    "> Dica: d√™ aten√ß√£o ao coeficiente de correla√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile1 = ProfileReport(joinDataframe(splited_signals[0]), title='signal 0 report', html={'style':{'full_width':True}})\n",
    "profile2 = ProfileReport(joinDataframe(splited_signals[4]), title='signal 4 report', html={'style':{'full_width':True}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033cba8dfe834c5fafe56b530e7b7319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(value='Number of va‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Report generated with <a href=\"https://github.com/pandas-profiling/pandas-profiling\">pandas-profiling</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile1.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a64b81b028848d4adbc9387cd4027a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(value='Number of va‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Report generated with <a href=\"https://github.com/pandas-profiling/pandas-profiling\">pandas-profiling</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile2.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile1.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile2.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "√à poss√≠vel notar que "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Realizar um estudo de relev√¢ncia de atributos utilzando as t√©cnicas exibidas na aula.\n",
    "\n",
    "Nesse momento utilize a base de dados `Clinical_data_09-09-19-processed.csv`. Uma breve descri√ß√£o da base:\n",
    "- Cont√©m um hist√≥rico dos registros de pacientes acometidos com uma determinada patologia.\n",
    "- Os registros s√£o variados, v√£o desde resposta de question√°rios m√©dicos de anamnese, por exemplo, \"*√â fumante nos √∫ltimos 5 anos?*\", \"*Faz uso de √°lcool constantemente?*\", at√© resultados de exames cl√≠nicos como ECG e Ecocardiograma.\n",
    "- O r√≥tulo dessa base √© a coluna `√ìbito`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregue a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) An√°lise explorat√≥ria na base de dados\n",
    "- Use a ferramenta `pandas-profiling` https://github.com/pandas-profiling/pandas-profiling\n",
    "- Fa√ßa um resumo do relat√≥rio, destacando os principais pontos gerados na base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Identicar qual a vari√°veis parecem influenciar no √≥bito dos pacientes :(\n",
    "- Utilize o c√≥digo `feature_selection_framework` https://github.com/navarmn/feature_selection_framework \n",
    "- Monte o resultado em um `DataFrame`, as colunas ser√£o referentes aos m√©todos e as linhas dever√£o ser os atributos. Coloque 1 quando o m√©todo indicar como relevante e 0 quando o m√©todo indicar com n√£o relevante;\n",
    "- Utilize o seguinte crit√©rio para validar um atributo como relevante: moda >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. QUEST√ÉO DESAFIO\n",
    "- Essa etapa n√£o entrar√° com atividade avaliativa, pois a base de dados a seguir n√£o √© t√£o bonita quanto parece ü§™. H√° muitas etapas de pr√©-processamento, agrupmaento e mais importante de tudo, o usu√°rio tem que fazer as duas tabelas `weekly-infos-before-shrink.csv` e `user-status-after-shrink.csv` conversarem entre si.\n",
    "- Fique √† vontade para tentar e para tirar d√∫vidas. üòä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse momento utilize a base de dados `weekly-infos-before-shrink.csv` e `user-status-after-shrink.csv`. Uma breve descri√ß√£o da base:\n",
    "- Essa base foi retirada de um servi√ßo de streaming de midia. Os atributos s√£o relativos a perfis de consumo de usu√°rios.\n",
    "- O objetivo √© realizar detec√ß√£o de *churn* (https://resultadosdigitais.com.br/blog/o-que-e-churn/)\n",
    "- Possui um registro de 17 semanas de uso e os r√≥tulos est√°o na tabela `user-status-after-shrink.csv`, que indicam se ao final do per√≠odo o usu√°rio cancelou e se manteve assinante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) An√°lise explorat√≥ria na base de dados\n",
    "- Use a ferramenta `pandas-profiling` https://github.com/pandas-profiling/pandas-profiling\n",
    "- Fa√ßa um resumo do relat√≥rio, destacando os principais pontos gerados na base.\n",
    "> Exiba a matriz de correla√ß√£o!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Identicar qual a vari√°veis parecem influenciar no cancelamento da assinatura.\n",
    "\n",
    "- Utilize o c√≥digo `feature_selection_framework` https://github.com/navarmn/feature_selection_framework \n",
    "- Monte o resultado em um `DataFrame`, as colunas ser√£o referentes aos m√©todos e as linhas dever√£o ser os atributos. Coloque 1 quando o m√©todo indicar como relevante e 0 quando o m√©todo indicar com n√£o relevante;\n",
    "- Utilize o seguinte crit√©rio para validar um atributo como relevante: moda >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python data science",
   "language": "python",
   "name": "python-data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
