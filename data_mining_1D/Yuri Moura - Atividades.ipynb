{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atividades\n",
    "===\n",
    "\n",
    "Essas atividade são relativas a aulas de extração de atributos e selecão de atributos. \n",
    "- Link para video: https://drive.google.com/file/d/13LLQGLt7QsjKshBXgUdJ4RVOT8N252cU/view\n",
    "- Link para apresentação: https://docs.google.com/presentation/d/1wctFgQe7TSlBEypZbVQqqsfrnpSgOeXPSO-mCJ6jIz4\n",
    "\n",
    "\n",
    "> Lembre de criar uma `virtualenv` com os `requirements.txt` do repositório.\n",
    "\n",
    "> Lembre de criar uma `kernel` do jupyter para seus desenvolvimentos\n",
    "\n",
    "> **MANTENHA** essa arquivo no local padrão do repositório. Detro da pasta **feature_extraction_and_feature_selection**.\n",
    "\n",
    "> Enviei apenas o seu notebook para correção. Não é necessário enviar nenhum outro arquivo. Siga o padrão `Atividades-<NOME-DO-ALUNO>.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Realizar a extração de atributos utilzando as técnicas Fourier e HOS nas bases de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dados de falhas em aerogeradores\n",
    "\n",
    "As orientações abaixo devem ser seguidas antes de iniciar os trabalhos\n",
    "\n",
    "> Todo os arquivos nomeados com `v000_ ... .csv` são referentes a essa base.\n",
    "\n",
    "> A classe referente ao dado está representada por uma TAG no nome do arquivo da seguinte forma: `v000_NORMAL_ ... .csv` é o dado referente a classe de funcionamento normal do gerador. A TAG `v000_SC_LI_LVL3_ ... .csv` é a classe referente a falha tipo 1 e continua. Não se preocupem com a ordem de enumeração das classes nesse momento.\n",
    "\n",
    "> Há 5 arquivos na pasta.\n",
    "\n",
    "> Utilizar as colunas a `Current_R`, `Current_S`, `Current_T` para realizar extração de atributos. Perceba que cada coluna é referente a uma sinal de corrente elétrica, portanto cada um são representados vetores de dimensões $1x50000$.\n",
    "\n",
    "> Antes de realizar a extração de atributos deve-se dividir cada sinal em 10 partes de tamanho $1x5000$. A ideia aqui é aumentar o número de amostra da base de dados por 10. Pense que cada parte é um recorte do sinal, e ao serem concatenadas retornarão o sinal original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing feature extraction module  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'feature_extraction_signal' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/navarmn/feature_extraction_signal.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction_signal.src import feature_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing pandas and others tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregue a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = os.path.join('.', 'datasets')\n",
    "DATAFILES = [\n",
    "    'v000_FAULT_SC_HI_LVL2_FR6000_FG5942_L000_0,6IN_SENSORC.csv',\n",
    "    'v000_FAULT_SC_LI_LVL3_FR4500_FG4365_L000_0,8IN_SENSORC.csv',\n",
    "    'v000_FAULT_SC_LI_LVL3_FR6000_FG5927_L000_0,4IN_SENSORC.csv',\n",
    "    'v000_NORMAL_FR4500_FG4385_L000_1,0IN_SENSORC.csv',\n",
    "    'v000_NORMAL_FR6000_FG5955_L000_0,5IN_SENSORC.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single sinals for simple tests\n",
    "sinal1 = pd.read_csv(os.path.join(dataset_folder, DATAFILES[0]))\n",
    "sinal2 = pd.read_csv(os.path.join(dataset_folder, DATAFILES[1]))\n",
    "sinal3 = pd.read_csv(os.path.join(dataset_folder, DATAFILES[2]))\n",
    "sinal4 = pd.read_csv(os.path.join(dataset_folder, DATAFILES[3]))\n",
    "sinal5 = pd.read_csv(os.path.join(dataset_folder, DATAFILES[4]))\n",
    "\n",
    "'''\n",
    "We are going to have an array which each element is a dataframe with the full signal\n",
    "'''\n",
    "\n",
    "signals = [pd.read_csv(os.path.join(dataset_folder, DATAFILES[x])).iloc[:, :3] for x in range(len(DATAFILES))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code below will split the dataframe in an array with N dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataframe(df, slices=10):\n",
    "    #collecting number of rows and columns\n",
    "    df_rows, df_columns = df.shape\n",
    "    \n",
    "    #defining the slice\n",
    "    slice = int(df_rows/slices)\n",
    "    \n",
    "    #defining variables to start spliting the dataframe\n",
    "    prev_slice, current_slice = 0, 0\n",
    "    slices_array = [] #array that will receive the slices\n",
    "    for x in range(slices):\n",
    "        #update the prev and current slice variables and append the slice to slices_array \n",
    "        prev_slice = current_slice\n",
    "        current_slice+=slice\n",
    "        slices_array.append(df.iloc[prev_slice:current_slice])\n",
    "    return slices_array    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining a sliced dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinDataframe(array_of_dfs):\n",
    "    dataframe = pd.DataFrame([])\n",
    "    for df in array_of_dfs:\n",
    "        dataframe = dataframe.append(df, ignore_index=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current_R</th>\n",
       "      <th>Current_S</th>\n",
       "      <th>Current_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.366486</td>\n",
       "      <td>1.117192</td>\n",
       "      <td>-1.372104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.570073</td>\n",
       "      <td>1.193545</td>\n",
       "      <td>-1.804737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.028144</td>\n",
       "      <td>0.964485</td>\n",
       "      <td>-1.473900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.206103</td>\n",
       "      <td>0.989936</td>\n",
       "      <td>-1.919258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.091765</td>\n",
       "      <td>0.735425</td>\n",
       "      <td>-1.550247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1.155386</td>\n",
       "      <td>-1.898767</td>\n",
       "      <td>0.803788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.799109</td>\n",
       "      <td>-1.338842</td>\n",
       "      <td>0.625644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.977247</td>\n",
       "      <td>-1.949669</td>\n",
       "      <td>1.058278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.595521</td>\n",
       "      <td>-1.402470</td>\n",
       "      <td>0.854686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.735488</td>\n",
       "      <td>-1.987846</td>\n",
       "      <td>1.160074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Current_R  Current_S  Current_T\n",
       "0      0.366486   1.117192  -1.372104\n",
       "1      0.570073   1.193545  -1.804737\n",
       "2      1.028144   0.964485  -1.473900\n",
       "3     -0.206103   0.989936  -1.919258\n",
       "4      1.091765   0.735425  -1.550247\n",
       "...         ...        ...        ...\n",
       "4995   1.155386  -1.898767   0.803788\n",
       "4996   0.799109  -1.338842   0.625644\n",
       "4997   0.977247  -1.949669   1.058278\n",
       "4998   0.595521  -1.402470   0.854686\n",
       "4999   0.735488  -1.987846   1.160074\n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Now we are going to split each signal, that by now are dataframes. So at the end of the process we\n",
    "will have an array which each element it is an another array with the sliced signals.\n",
    "\n",
    "[[slice1DF, slice2DF, ..., slice10DF], ...]\n",
    "\n",
    "'''\n",
    "\n",
    "splited_signals = []\n",
    "for signal in signals:\n",
    "    splited_signals.append(splitDataframe(signal))\n",
    "\n",
    "    \n",
    "#selecting just the three fisrt columns of the splited dataframe\n",
    "#array_of_dfs = [df.iloc[:, :3] for df in array_of_dfs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Comparativo da média do sinal e sua distribuição\n",
    "\n",
    "- Realize o calculo da média e desvio padrão em cada um dos sinais e exiba o resultado em um dataframe. Discuta suas conclusões.\n",
    "\n",
    "**help**: utilize as funcões nativas do numpy ou do pandas. Lembre que o sinal é uma senoide, qual a média em uma senoide simétrica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_Current_R</th>\n",
       "      <th>mean_Current_S</th>\n",
       "      <th>mean_Current_T</th>\n",
       "      <th>std_Current_R</th>\n",
       "      <th>std_Current_S</th>\n",
       "      <th>std_Current_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.009033</td>\n",
       "      <td>0.009121</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>1.557126</td>\n",
       "      <td>1.293221</td>\n",
       "      <td>1.119889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.024040</td>\n",
       "      <td>0.018686</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>1.548669</td>\n",
       "      <td>1.285848</td>\n",
       "      <td>1.106367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.004320</td>\n",
       "      <td>0.013443</td>\n",
       "      <td>-0.004654</td>\n",
       "      <td>1.568302</td>\n",
       "      <td>1.296482</td>\n",
       "      <td>1.104084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.006066</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>1.567200</td>\n",
       "      <td>1.305422</td>\n",
       "      <td>1.099161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.018729</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>0.007681</td>\n",
       "      <td>1.561267</td>\n",
       "      <td>1.290381</td>\n",
       "      <td>1.129608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.004880</td>\n",
       "      <td>0.017815</td>\n",
       "      <td>-0.005135</td>\n",
       "      <td>1.550151</td>\n",
       "      <td>1.284158</td>\n",
       "      <td>1.114267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.007053</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>1.558204</td>\n",
       "      <td>1.287793</td>\n",
       "      <td>1.107035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.005135</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>1.567012</td>\n",
       "      <td>1.298340</td>\n",
       "      <td>1.103462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.019887</td>\n",
       "      <td>0.018602</td>\n",
       "      <td>0.003568</td>\n",
       "      <td>1.572879</td>\n",
       "      <td>1.299555</td>\n",
       "      <td>1.104010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.008970</td>\n",
       "      <td>0.016138</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>1.559266</td>\n",
       "      <td>1.293978</td>\n",
       "      <td>1.121942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_Current_R  mean_Current_S  mean_Current_T  std_Current_R  \\\n",
       "0       -0.009033        0.009121        0.001576       1.557126   \n",
       "1       -0.024040        0.018686        0.003087       1.548669   \n",
       "2       -0.004320        0.013443       -0.004654       1.568302   \n",
       "3       -0.006066        0.005207        0.003678       1.567200   \n",
       "4       -0.018729        0.015649        0.007681       1.561267   \n",
       "5       -0.004880        0.017815       -0.005135       1.550151   \n",
       "6       -0.007053        0.009974       -0.003980       1.558204   \n",
       "7       -0.005135        0.008126        0.005938       1.567012   \n",
       "8       -0.019887        0.018602        0.003568       1.572879   \n",
       "9       -0.008970        0.016138        0.001008       1.559266   \n",
       "\n",
       "   std_Current_S  std_Current_T  \n",
       "0       1.293221       1.119889  \n",
       "1       1.285848       1.106367  \n",
       "2       1.296482       1.104084  \n",
       "3       1.305422       1.099161  \n",
       "4       1.290381       1.129608  \n",
       "5       1.284158       1.114267  \n",
       "6       1.287793       1.107035  \n",
       "7       1.298340       1.103462  \n",
       "8       1.299555       1.104010  \n",
       "9       1.293978       1.121942  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mean_and_std(array_of_dfs, how='slices'):\n",
    "    '''\n",
    "    Two types of use:\n",
    "    full: Use the full signal to calculate the mean and the standard deviation.\n",
    "    \n",
    "    slices: Use the slices to calculate the mean and the standard deviation and return the result\n",
    "    of each slice as a Dataframe\n",
    "    '''\n",
    "\n",
    "    #dataframes that will be merged\n",
    "    df_mean, df_std = pd.DataFrame([]),pd.DataFrame([])\n",
    "    \n",
    "    #dataframe that will be returned\n",
    "    return_df = pd.DataFrame([])\n",
    "    \n",
    "    #joins the dataframe\n",
    "    dataframe = joinDataframe(array_of_dfs)\n",
    "\n",
    "    #getting columns names and changing them\n",
    "    cols_names = dataframe.columns\n",
    "    mean_names, std_names = ['mean_'+name for name in cols_names],['std_'+name for name in cols_names]\n",
    "    \n",
    "    if how == 'full':\n",
    "        \n",
    "        #calculating the mean and the standard deviation of the current dataframe(df)\n",
    "        serie_mean, serie_std = dataframe.mean(), dataframe.std()\n",
    "        \n",
    "        #changing the index of the series\n",
    "        serie_mean.index,serie_std.index = mean_names,std_names\n",
    "        \n",
    "        #returns the mean series concatenated with the std series\n",
    "        return pd.concat([serie_mean, serie_std], join='outer', sort=False)\n",
    "\n",
    "    if how == 'slices':\n",
    "        #deleting dataframe variable that will not be used anymore\n",
    "        del dataframe\n",
    "        \n",
    "        for df in array_of_dfs:\n",
    "\n",
    "            #calculating the mean and the standard deviation of the current dataframe(df)\n",
    "            serie_mean, serie_std = df.mean(), df.std()\n",
    "\n",
    "            #changing the index of the series\n",
    "            serie_mean.index,serie_std.index = mean_names,std_names\n",
    "\n",
    "            #appending the serie_mean and the serie_std to df_mean and df_std, respectively\n",
    "            df_mean, df_std = df_mean.append(serie_mean, ignore_index=True), df_std.append(serie_std, ignore_index=True, sort=False)\n",
    "    \n",
    "        return_df = df_mean.merge(df_std, left_index=True, right_index=True, how='outer')\n",
    "        \n",
    "            \n",
    "    return return_df\n",
    "\n",
    "answer = mean_and_std(array_of_dfs, how='slices')\n",
    "display(answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "È possível notar que temos a média do sinal por volta de zero por causa de sua característica periódica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Extração de atributos no sinal\n",
    "\n",
    "- Utilize o código de `feature_extraction_signal` em: https://github.com/navarmn/feature_extraction_signal\n",
    "- Use as classes `Fourier` e `HOS` de maneira adequada. Lembre do método `.transform()`.\n",
    "- Na classe `Fourier`utilize os parâmetros: `fs=5000`; o valor de fundamental está na TAG do nome em `_FG5955_`significa `fundamental=59.55`. `harmonics=(0.5, 1, 1.5, 2.5, 3, 5, 7)`, mas sintam-se à vontade para buscar outras harmônicas;\n",
    "- Os rótulos devem serem impostos de acordo com a descrição da tag feita cima. \n",
    "- Monte um dataframe que contenham os atributos em cada coluna e a útlima com o rótulo. Concatene os artibutos extraídos da `Current_R`, `Current_S` e `Current_T`.\n",
    "- Deverá ser feito um dataframe para os atributos de Fourier e um para os atributos de HOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Análise exploratória na base criada com os extratores de atributos\n",
    "- Use a ferramenta `pandas-profiling` https://github.com/pandas-profiling/pandas-profiling\n",
    "- Faça um resumo do relatório, destacando os principais pontos gerados na base.\n",
    "- Faça uma análise para cada uma das bases:\n",
    "    1. Features criada com Fourier\n",
    "    2. Features criada com HOS\n",
    "    3. Combinação das duas features (Fourier + HOS). \n",
    "> Dica: dê atenção ao coeficiente de correlação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Realizar um estudo de relevância de atributos utilzando as técnicas exibidas na aula.\n",
    "\n",
    "Nesse momento utilize a base de dados `Clinical_data_09-09-19-processed.csv`. Uma breve descrição da base:\n",
    "- Contém um histórico dos registros de pacientes acometidos com uma determinada patologia.\n",
    "- Os registros são variados, vão desde resposta de questionários médicos de anamnese, por exemplo, \"*É fumante nos últimos 5 anos?*\", \"*Faz uso de álcool constantemente?*\", até resultados de exames clínicos como ECG e Ecocardiograma.\n",
    "- O rótulo dessa base é a coluna `Óbito`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregue a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Análise exploratória na base de dados\n",
    "- Use a ferramenta `pandas-profiling` https://github.com/pandas-profiling/pandas-profiling\n",
    "- Faça um resumo do relatório, destacando os principais pontos gerados na base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Identicar qual a variáveis parecem influenciar no óbito dos pacientes :(\n",
    "- Utilize o código `feature_selection_framework` https://github.com/navarmn/feature_selection_framework \n",
    "- Monte o resultado em um `DataFrame`, as colunas serão referentes aos métodos e as linhas deverão ser os atributos. Coloque 1 quando o método indicar como relevante e 0 quando o método indicar com não relevante;\n",
    "- Utilize o seguinte critério para validar um atributo como relevante: moda >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. QUESTÃO DESAFIO\n",
    "- Essa etapa não entrará com atividade avaliativa, pois a base de dados a seguir não é tão bonita quanto parece 🤪. Há muitas etapas de pré-processamento, agrupmaento e mais importante de tudo, o usuário tem que fazer as duas tabelas `weekly-infos-before-shrink.csv` e `user-status-after-shrink.csv` conversarem entre si.\n",
    "- Fique à vontade para tentar e para tirar dúvidas. 😊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse momento utilize a base de dados `weekly-infos-before-shrink.csv` e `user-status-after-shrink.csv`. Uma breve descrição da base:\n",
    "- Essa base foi retirada de um serviço de streaming de midia. Os atributos são relativos a perfis de consumo de usuários.\n",
    "- O objetivo é realizar detecção de *churn* (https://resultadosdigitais.com.br/blog/o-que-e-churn/)\n",
    "- Possui um registro de 17 semanas de uso e os rótulos estáo na tabela `user-status-after-shrink.csv`, que indicam se ao final do período o usuário cancelou e se manteve assinante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Análise exploratória na base de dados\n",
    "- Use a ferramenta `pandas-profiling` https://github.com/pandas-profiling/pandas-profiling\n",
    "- Faça um resumo do relatório, destacando os principais pontos gerados na base.\n",
    "> Exiba a matriz de correlação!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Identicar qual a variáveis parecem influenciar no cancelamento da assinatura.\n",
    "\n",
    "- Utilize o código `feature_selection_framework` https://github.com/navarmn/feature_selection_framework \n",
    "- Monte o resultado em um `DataFrame`, as colunas serão referentes aos métodos e as linhas deverão ser os atributos. Coloque 1 quando o método indicar como relevante e 0 quando o método indicar com não relevante;\n",
    "- Utilize o seguinte critério para validar um atributo como relevante: moda >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python data science",
   "language": "python",
   "name": "python-data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
