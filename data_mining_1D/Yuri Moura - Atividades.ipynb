{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atividades\n",
    "===\n",
    "\n",
    "Essas atividade são relativas a aulas de extração de atributos e selecão de atributos. \n",
    "- Link para video: https://drive.google.com/file/d/13LLQGLt7QsjKshBXgUdJ4RVOT8N252cU/view\n",
    "- Link para apresentação: https://docs.google.com/presentation/d/1wctFgQe7TSlBEypZbVQqqsfrnpSgOeXPSO-mCJ6jIz4\n",
    "\n",
    "\n",
    "> Lembre de criar uma `virtualenv` com os `requirements.txt` do repositório.\n",
    "\n",
    "> Lembre de criar uma `kernel` do jupyter para seus desenvolvimentos\n",
    "\n",
    "> **MANTENHA** essa arquivo no local padrão do repositório. Detro da pasta **feature_extraction_and_feature_selection**.\n",
    "\n",
    "> Enviei apenas o seu notebook para correção. Não é necessário enviar nenhum outro arquivo. Siga o padrão `Atividades-<NOME-DO-ALUNO>.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Realizar a extração de atributos utilzando as técnicas Fourier e HOS nas bases de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dados de falhas em aerogeradores\n",
    "\n",
    "As orientações abaixo devem ser seguidas antes de iniciar os trabalhos\n",
    "\n",
    "> Todo os arquivos nomeados com `v000_ ... .csv` são referentes a essa base.\n",
    "\n",
    "> A classe referente ao dado está representada por uma TAG no nome do arquivo da seguinte forma: `v000_NORMAL_ ... .csv` é o dado referente a classe de funcionamento normal do gerador. A TAG `v000_SC_LI_LVL3_ ... .csv` é a classe referente a falha tipo 1 e continua. Não se preocupem com a ordem de enumeração das classes nesse momento.\n",
    "\n",
    "> Há 5 arquivos na pasta.\n",
    "\n",
    "> Utilizar as colunas a `Current_R`, `Current_S`, `Current_T` para realizar extração de atributos. Perceba que cada coluna é referente a uma sinal de corrente elétrica, portanto cada um são representados vetores de dimensões $1x50000$.\n",
    "\n",
    "> Antes de realizar a extração de atributos deve-se dividir cada sinal em 10 partes de tamanho $1x5000$. A ideia aqui é aumentar o número de amostra da base de dados por 10. Pense que cada parte é um recorte do sinal, e ao serem concatenadas retornarão o sinal original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing feature extraction module  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/navarmn/feature_extraction_signal.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction_signal.src import feature_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing pandas and others tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregue a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = os.path.join('.', 'datasets')\n",
    "DATAFILES = [\n",
    "    'v000_FAULT_SC_HI_LVL2_FR6000_FG5942_L000_0,6IN_SENSORC.csv',\n",
    "    'v000_FAULT_SC_LI_LVL3_FR4500_FG4365_L000_0,8IN_SENSORC.csv',\n",
    "    'v000_FAULT_SC_LI_LVL3_FR6000_FG5927_L000_0,4IN_SENSORC.csv',\n",
    "    'v000_NORMAL_FR4500_FG4385_L000_1,0IN_SENSORC.csv',\n",
    "    'v000_NORMAL_FR6000_FG5955_L000_0,5IN_SENSORC.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(dataset_folder, DATAFILES[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code below will split the dataframe in an array with N dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataframe(df, slices=10):\n",
    "    #collecting number of rows and columns\n",
    "    df_rows, df_columns = df.shape\n",
    "    \n",
    "    #defining the slice\n",
    "    slice = int(df_rows/slices)\n",
    "    \n",
    "    #defining variables to start spliting the dataframe\n",
    "    prev_slice, current_slice = 0, 0\n",
    "    slices_array = [] #array that will receive the slices\n",
    "    for x in range(slices):\n",
    "        #update the prev and current slice variables and append the slice to slices_array \n",
    "        prev_slice = current_slice\n",
    "        current_slice+=slice\n",
    "        slices_array.append(df.iloc[prev_slice:current_slice])\n",
    "    return slices_array    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### joining a sliced dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinDataframe(array_of_dfs):\n",
    "    dataframe = pd.DataFrame([])\n",
    "    for df in array_of_dfs:\n",
    "        dataframe = dataframe.append(df, ignore_index=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_of_dfs = splitDataframe(df)\n",
    "\n",
    "array_of_dfs = [df.iloc[:, :3] for df in array_of_dfs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Comparativo da média do sinal e sua distribuição\n",
    "\n",
    "- Realize o calculo da média e desvio padrão em cada um dos sinais e exiba o resultado em um dataframe. Discuta suas conclusões.\n",
    "\n",
    "**help**: utilize as funcões nativas do numpy ou do pandas. Lembre que o sinal é uma senoide, qual a média em uma senoide simétrica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muriyoura/Desktop/lapisco_training/data_mining_1D/1DfeEx/lib/python3.6/site-packages/ipykernel_launcher.py:47: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def mean_and_std(array_of_dfs, how='full'):\n",
    "    '''\n",
    "    Two types of use:\n",
    "    full: Use the full signal to calculate the mean and the standard deviation.\n",
    "    \n",
    "    slices: Use the slices to calculate the mean and the standard deviation and return the result\n",
    "    of each slice as a Dataframe\n",
    "    '''\n",
    "\n",
    "    #dataframes that will be merged\n",
    "    df_mean, df_std = pd.DataFrame([]),pd.DataFrame([])\n",
    "    \n",
    "    #dataframe that will be returned\n",
    "    return_df = pd.DataFrame([])\n",
    "    \n",
    "    if how == 'full':\n",
    "        dataframe = joinDataframe(array_of_dfs)\n",
    "        print(type(dataframe))\n",
    "        #getting columns names and changing them\n",
    "        cols_names = dataframe.columns\n",
    "        mean_names, std_names = ['mean_'+name for name in cols_names],['std_'+name for name in cols_names]\n",
    "        \n",
    "        #calculating the mean and the standard deviation of the current dataframe(df)\n",
    "        serie_mean, serie_std = dataframe.mean(), dataframe.std()\n",
    "        \n",
    "        #changing the index of the series\n",
    "        serie_mean.index,serie_std.index = mean_names,std_names\n",
    "        \n",
    "        return pd.concat([serie_mean, serie_std], join='outer')\n",
    "\n",
    "    if how == 'slices':\n",
    "        for df in array_of_dfs:\n",
    "            #getting columns names and changing them\n",
    "            cols_names = df.columns\n",
    "            mean_names, std_names = ['mean_'+name for name in cols_names],['std_'+name for name in cols_names]\n",
    "\n",
    "            #calculating the mean and the standard deviation of the current dataframe(df)\n",
    "            serie_mean, serie_std = df.mean(), df.std()\n",
    "\n",
    "            #changing the index of the series\n",
    "            serie_mean.index,serie_std.index = mean_names,std_names\n",
    "\n",
    "            #appending the serie_mean and the serie_std to\n",
    "            df_mean, df_std = df_mean.append(serie_mean, ignore_index=True), df_std.append(serie_std, ignore_index=True)\n",
    "\n",
    "            #concatenating the series and adding it to return_df\n",
    "            ctrl = pd.concat([df_mean, df_std], join='outer')\n",
    "            return_df = return_df.append(ctrl, ignore_index=True)\n",
    "    return return_df\n",
    "\n",
    "answer = mean_and_std(array_of_dfs, how='slices')\n",
    "#display(answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Extração de atributos no sinal\n",
    "\n",
    "- Utilize o código de `feature_extraction_signal` em: https://github.com/navarmn/feature_extraction_signal\n",
    "- Use as classes `Fourier` e `HOS` de maneira adequada. Lembre do método `.transform()`.\n",
    "- Na classe `Fourier`utilize os parâmetros: `fs=5000`; o valor de fundamental está na TAG do nome em `_FG5955_`significa `fundamental=59.55`. `harmonics=(0.5, 1, 1.5, 2.5, 3, 5, 7)`, mas sintam-se à vontade para buscar outras harmônicas;\n",
    "- Os rótulos devem serem impostos de acordo com a descrição da tag feita cima. \n",
    "- Monte um dataframe que contenham os atributos em cada coluna e a útlima com o rótulo. Concatene os artibutos extraídos da `Current_R`, `Current_S` e `Current_T`.\n",
    "- Deverá ser feito um dataframe para os atributos de Fourier e um para os atributos de HOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Análise exploratória na base criada com os extratores de atributos\n",
    "- Use a ferramenta `pandas-profiling` https://github.com/pandas-profiling/pandas-profiling\n",
    "- Faça um resumo do relatório, destacando os principais pontos gerados na base.\n",
    "- Faça uma análise para cada uma das bases:\n",
    "    1. Features criada com Fourier\n",
    "    2. Features criada com HOS\n",
    "    3. Combinação das duas features (Fourier + HOS). \n",
    "> Dica: dê atenção ao coeficiente de correlação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Realizar um estudo de relevância de atributos utilzando as técnicas exibidas na aula.\n",
    "\n",
    "Nesse momento utilize a base de dados `Clinical_data_09-09-19-processed.csv`. Uma breve descrição da base:\n",
    "- Contém um histórico dos registros de pacientes acometidos com uma determinada patologia.\n",
    "- Os registros são variados, vão desde resposta de questionários médicos de anamnese, por exemplo, \"*É fumante nos últimos 5 anos?*\", \"*Faz uso de álcool constantemente?*\", até resultados de exames clínicos como ECG e Ecocardiograma.\n",
    "- O rótulo dessa base é a coluna `Óbito`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregue a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Análise exploratória na base de dados\n",
    "- Use a ferramenta `pandas-profiling` https://github.com/pandas-profiling/pandas-profiling\n",
    "- Faça um resumo do relatório, destacando os principais pontos gerados na base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Identicar qual a variáveis parecem influenciar no óbito dos pacientes :(\n",
    "- Utilize o código `feature_selection_framework` https://github.com/navarmn/feature_selection_framework \n",
    "- Monte o resultado em um `DataFrame`, as colunas serão referentes aos métodos e as linhas deverão ser os atributos. Coloque 1 quando o método indicar como relevante e 0 quando o método indicar com não relevante;\n",
    "- Utilize o seguinte critério para validar um atributo como relevante: moda >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. QUESTÃO DESAFIO\n",
    "- Essa etapa não entrará com atividade avaliativa, pois a base de dados a seguir não é tão bonita quanto parece 🤪. Há muitas etapas de pré-processamento, agrupmaento e mais importante de tudo, o usuário tem que fazer as duas tabelas `weekly-infos-before-shrink.csv` e `user-status-after-shrink.csv` conversarem entre si.\n",
    "- Fique à vontade para tentar e para tirar dúvidas. 😊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse momento utilize a base de dados `weekly-infos-before-shrink.csv` e `user-status-after-shrink.csv`. Uma breve descrição da base:\n",
    "- Essa base foi retirada de um serviço de streaming de midia. Os atributos são relativos a perfis de consumo de usuários.\n",
    "- O objetivo é realizar detecção de *churn* (https://resultadosdigitais.com.br/blog/o-que-e-churn/)\n",
    "- Possui um registro de 17 semanas de uso e os rótulos estáo na tabela `user-status-after-shrink.csv`, que indicam se ao final do período o usuário cancelou e se manteve assinante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Análise exploratória na base de dados\n",
    "- Use a ferramenta `pandas-profiling` https://github.com/pandas-profiling/pandas-profiling\n",
    "- Faça um resumo do relatório, destacando os principais pontos gerados na base.\n",
    "> Exiba a matriz de correlação!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Identicar qual a variáveis parecem influenciar no cancelamento da assinatura.\n",
    "\n",
    "- Utilize o código `feature_selection_framework` https://github.com/navarmn/feature_selection_framework \n",
    "- Monte o resultado em um `DataFrame`, as colunas serão referentes aos métodos e as linhas deverão ser os atributos. Coloque 1 quando o método indicar como relevante e 0 quando o método indicar com não relevante;\n",
    "- Utilize o seguinte critério para validar um atributo como relevante: moda >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python data science",
   "language": "python",
   "name": "python-data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
