{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atividades\n",
    "===\n",
    "\n",
    "Essas atividade s√£o relativas a aulas de extra√ß√£o de atributos e selec√£o de atributos. \n",
    "- Link para video: https://drive.google.com/file/d/13LLQGLt7QsjKshBXgUdJ4RVOT8N252cU/view\n",
    "- Link para apresenta√ß√£o: https://docs.google.com/presentation/d/1wctFgQe7TSlBEypZbVQqqsfrnpSgOeXPSO-mCJ6jIz4\n",
    "\n",
    "\n",
    "> Lembre de criar uma `virtualenv` com os `requirements.txt` do reposit√≥rio.\n",
    "\n",
    "> Lembre de criar uma `kernel` do jupyter para seus desenvolvimentos\n",
    "\n",
    "> **MANTENHA** essa arquivo no local padr√£o do reposit√≥rio. Detro da pasta **feature_extraction_and_feature_selection**.\n",
    "\n",
    "> Enviei apenas o seu notebook para corre√ß√£o. N√£o √© necess√°rio enviar nenhum outro arquivo. Siga o padr√£o `Atividades-<NOME-DO-ALUNO>.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Realizar a extra√ß√£o de atributos utilzando as t√©cnicas Fourier e HOS nas bases de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dados de falhas em aerogeradores\n",
    "\n",
    "As orienta√ß√µes abaixo devem ser seguidas antes de iniciar os trabalhos\n",
    "\n",
    "> Todo os arquivos nomeados com `v000_ ... .csv` s√£o referentes a essa base.\n",
    "\n",
    "> A classe referente ao dado est√° representada por uma TAG no nome do arquivo da seguinte forma: `v000_NORMAL_ ... .csv` √© o dado referente a classe de funcionamento normal do gerador. A TAG `v000_SC_LI_LVL3_ ... .csv` √© a classe referente a falha tipo 1 e continua. N√£o se preocupem com a ordem de enumera√ß√£o das classes nesse momento.\n",
    "\n",
    "> H√° 5 arquivos na pasta.\n",
    "\n",
    "> Utilizar as colunas a `Current_R`, `Current_S`, `Current_T` para realizar extra√ß√£o de atributos. Perceba que cada coluna √© referente a uma sinal de corrente el√©trica, portanto cada um s√£o representados vetores de dimens√µes $1x50000$.\n",
    "\n",
    "> Antes de realizar a extra√ß√£o de atributos deve-se dividir cada sinal em 10 partes de tamanho $1x5000$. A ideia aqui √© aumentar o n√∫mero de amostra da base de dados por 10. Pense que cada parte √© um recorte do sinal, e ao serem concatenadas retornar√£o o sinal original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing feature extraction module  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/navarmn/feature_extraction_signal.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extraction_signal.src import feature_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing pandas and others tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregue a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = os.path.join('.', 'datasets')\n",
    "DATAFILES = [\n",
    "    'v000_FAULT_SC_HI_LVL2_FR6000_FG5942_L000_0,6IN_SENSORC.csv',\n",
    "    'v000_FAULT_SC_LI_LVL3_FR4500_FG4365_L000_0,8IN_SENSORC.csv',\n",
    "    'v000_FAULT_SC_LI_LVL3_FR6000_FG5927_L000_0,4IN_SENSORC.csv',\n",
    "    'v000_NORMAL_FR4500_FG4385_L000_1,0IN_SENSORC.csv',\n",
    "    'v000_NORMAL_FR6000_FG5955_L000_0,5IN_SENSORC.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(dataset_folder, DATAFILES[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code below will split the dataframe in an array with N dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataframe(df, slices=10):\n",
    "    #collecting number of rows and columns\n",
    "    df_rows, df_columns = df.shape\n",
    "    \n",
    "    #defining the slice\n",
    "    slice = int(df_rows/slices)\n",
    "    \n",
    "    #defining variables to start spliting the dataframe\n",
    "    prev_slice, current_slice = 0, 0\n",
    "    slices_array = [] #array that will receive the slices\n",
    "    for x in range(slices):\n",
    "        #update the prev and current slice variables and append the slice to slices_array \n",
    "        prev_slice = current_slice\n",
    "        current_slice+=slice\n",
    "        slices_array.append(df.iloc[prev_slice:current_slice])\n",
    "    return slices_array    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### joining a sliced dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinDataframe(array_of_dfs):\n",
    "    dataframe = pd.DataFrame([])\n",
    "    for df in array_of_dfs:\n",
    "        dataframe = dataframe.append(df, ignore_index=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_of_dfs = splitDataframe(df)\n",
    "\n",
    "array_of_dfs = [df.iloc[:, :3] for df in array_of_dfs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Comparativo da m√©dia do sinal e sua distribui√ß√£o\n",
    "\n",
    "- Realize o calculo da m√©dia e desvio padr√£o em cada um dos sinais e exiba o resultado em um dataframe. Discuta suas conclus√µes.\n",
    "\n",
    "**help**: utilize as func√µes nativas do numpy ou do pandas. Lembre que o sinal √© uma senoide, qual a m√©dia em uma senoide sim√©trica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muriyoura/Desktop/lapisco_training/data_mining_1D/1DfeEx/lib/python3.6/site-packages/ipykernel_launcher.py:47: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def mean_and_std(array_of_dfs, how='full'):\n",
    "    '''\n",
    "    Two types of use:\n",
    "    full: Use the full signal to calculate the mean and the standard deviation.\n",
    "    \n",
    "    slices: Use the slices to calculate the mean and the standard deviation and return the result\n",
    "    of each slice as a Dataframe\n",
    "    '''\n",
    "\n",
    "    #dataframes that will be merged\n",
    "    df_mean, df_std = pd.DataFrame([]),pd.DataFrame([])\n",
    "    \n",
    "    #dataframe that will be returned\n",
    "    return_df = pd.DataFrame([])\n",
    "    \n",
    "    if how == 'full':\n",
    "        dataframe = joinDataframe(array_of_dfs)\n",
    "        print(type(dataframe))\n",
    "        #getting columns names and changing them\n",
    "        cols_names = dataframe.columns\n",
    "        mean_names, std_names = ['mean_'+name for name in cols_names],['std_'+name for name in cols_names]\n",
    "        \n",
    "        #calculating the mean and the standard deviation of the current dataframe(df)\n",
    "        serie_mean, serie_std = dataframe.mean(), dataframe.std()\n",
    "        \n",
    "        #changing the index of the series\n",
    "        serie_mean.index,serie_std.index = mean_names,std_names\n",
    "        \n",
    "        return pd.concat([serie_mean, serie_std], join='outer')\n",
    "\n",
    "    if how == 'slices':\n",
    "        for df in array_of_dfs:\n",
    "            #getting columns names and changing them\n",
    "            cols_names = df.columns\n",
    "            mean_names, std_names = ['mean_'+name for name in cols_names],['std_'+name for name in cols_names]\n",
    "\n",
    "            #calculating the mean and the standard deviation of the current dataframe(df)\n",
    "            serie_mean, serie_std = df.mean(), df.std()\n",
    "\n",
    "            #changing the index of the series\n",
    "            serie_mean.index,serie_std.index = mean_names,std_names\n",
    "\n",
    "            #appending the serie_mean and the serie_std to\n",
    "            df_mean, df_std = df_mean.append(serie_mean, ignore_index=True), df_std.append(serie_std, ignore_index=True)\n",
    "\n",
    "            #concatenating the series and adding it to return_df\n",
    "            ctrl = pd.concat([df_mean, df_std], join='outer')\n",
    "            return_df = return_df.append(ctrl, ignore_index=True)\n",
    "    return return_df\n",
    "\n",
    "answer = mean_and_std(array_of_dfs, how='slices')\n",
    "#display(answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Extra√ß√£o de atributos no sinal\n",
    "\n",
    "- Utilize o c√≥digo de `feature_extraction_signal` em: https://github.com/navarmn/feature_extraction_signal\n",
    "- Use as classes `Fourier` e `HOS` de maneira adequada. Lembre do m√©todo `.transform()`.\n",
    "- Na classe `Fourier`utilize os par√¢metros: `fs=5000`; o valor de fundamental est√° na TAG do nome em `_FG5955_`significa `fundamental=59.55`. `harmonics=(0.5, 1, 1.5, 2.5, 3, 5, 7)`, mas sintam-se √† vontade para buscar outras harm√¥nicas;\n",
    "- Os r√≥tulos devem serem impostos de acordo com a descri√ß√£o da tag feita cima. \n",
    "- Monte um dataframe que contenham os atributos em cada coluna e a √∫tlima com o r√≥tulo. Concatene os artibutos extra√≠dos da `Current_R`, `Current_S` e `Current_T`.\n",
    "- Dever√° ser feito um dataframe para os atributos de Fourier e um para os atributos de HOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) An√°lise explorat√≥ria na base criada com os extratores de atributos\n",
    "- Use a ferramenta `pandas-profiling` https://github.com/pandas-profiling/pandas-profiling\n",
    "- Fa√ßa um resumo do relat√≥rio, destacando os principais pontos gerados na base.\n",
    "- Fa√ßa uma an√°lise para cada uma das bases:\n",
    "    1. Features criada com Fourier\n",
    "    2. Features criada com HOS\n",
    "    3. Combina√ß√£o das duas features (Fourier + HOS). \n",
    "> Dica: d√™ aten√ß√£o ao coeficiente de correla√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Realizar um estudo de relev√¢ncia de atributos utilzando as t√©cnicas exibidas na aula.\n",
    "\n",
    "Nesse momento utilize a base de dados `Clinical_data_09-09-19-processed.csv`. Uma breve descri√ß√£o da base:\n",
    "- Cont√©m um hist√≥rico dos registros de pacientes acometidos com uma determinada patologia.\n",
    "- Os registros s√£o variados, v√£o desde resposta de question√°rios m√©dicos de anamnese, por exemplo, \"*√â fumante nos √∫ltimos 5 anos?*\", \"*Faz uso de √°lcool constantemente?*\", at√© resultados de exames cl√≠nicos como ECG e Ecocardiograma.\n",
    "- O r√≥tulo dessa base √© a coluna `√ìbito`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregue a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) An√°lise explorat√≥ria na base de dados\n",
    "- Use a ferramenta `pandas-profiling` https://github.com/pandas-profiling/pandas-profiling\n",
    "- Fa√ßa um resumo do relat√≥rio, destacando os principais pontos gerados na base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Identicar qual a vari√°veis parecem influenciar no √≥bito dos pacientes :(\n",
    "- Utilize o c√≥digo `feature_selection_framework` https://github.com/navarmn/feature_selection_framework \n",
    "- Monte o resultado em um `DataFrame`, as colunas ser√£o referentes aos m√©todos e as linhas dever√£o ser os atributos. Coloque 1 quando o m√©todo indicar como relevante e 0 quando o m√©todo indicar com n√£o relevante;\n",
    "- Utilize o seguinte crit√©rio para validar um atributo como relevante: moda >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. QUEST√ÉO DESAFIO\n",
    "- Essa etapa n√£o entrar√° com atividade avaliativa, pois a base de dados a seguir n√£o √© t√£o bonita quanto parece ü§™. H√° muitas etapas de pr√©-processamento, agrupmaento e mais importante de tudo, o usu√°rio tem que fazer as duas tabelas `weekly-infos-before-shrink.csv` e `user-status-after-shrink.csv` conversarem entre si.\n",
    "- Fique √† vontade para tentar e para tirar d√∫vidas. üòä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse momento utilize a base de dados `weekly-infos-before-shrink.csv` e `user-status-after-shrink.csv`. Uma breve descri√ß√£o da base:\n",
    "- Essa base foi retirada de um servi√ßo de streaming de midia. Os atributos s√£o relativos a perfis de consumo de usu√°rios.\n",
    "- O objetivo √© realizar detec√ß√£o de *churn* (https://resultadosdigitais.com.br/blog/o-que-e-churn/)\n",
    "- Possui um registro de 17 semanas de uso e os r√≥tulos est√°o na tabela `user-status-after-shrink.csv`, que indicam se ao final do per√≠odo o usu√°rio cancelou e se manteve assinante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) An√°lise explorat√≥ria na base de dados\n",
    "- Use a ferramenta `pandas-profiling` https://github.com/pandas-profiling/pandas-profiling\n",
    "- Fa√ßa um resumo do relat√≥rio, destacando os principais pontos gerados na base.\n",
    "> Exiba a matriz de correla√ß√£o!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Identicar qual a vari√°veis parecem influenciar no cancelamento da assinatura.\n",
    "\n",
    "- Utilize o c√≥digo `feature_selection_framework` https://github.com/navarmn/feature_selection_framework \n",
    "- Monte o resultado em um `DataFrame`, as colunas ser√£o referentes aos m√©todos e as linhas dever√£o ser os atributos. Coloque 1 quando o m√©todo indicar como relevante e 0 quando o m√©todo indicar com n√£o relevante;\n",
    "- Utilize o seguinte crit√©rio para validar um atributo como relevante: moda >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python data science",
   "language": "python",
   "name": "python-data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
